"""
ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„œë¹„ìŠ¤
ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, ì•Œë¦¼ ë°œì†¡, ë©”íŠ¸ë¦­ ìˆ˜ì§‘
"""

import logging
import asyncio
import time
import json
import os
from typing import Dict, List, Optional, Any, Callable, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import psutil
import aiofiles

logger = logging.getLogger(__name__)

class AlertSeverity(Enum):
    """ì•Œë¦¼ ì‹¬ê°ë„"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AlertChannel(Enum):
    """ì•Œë¦¼ ì±„ë„"""
    LOG = "log"
    FILE = "file"
    EMAIL = "email"
    WEBHOOK = "webhook"
    SLACK = "slack"

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ ìœ í˜•"""
    COUNTER = "counter"      # ëˆ„ì ê°’ (ê±°ë˜ íšŸìˆ˜ ë“±)
    GAUGE = "gauge"          # í˜„ì¬ê°’ (CPU ì‚¬ìš©ë¥  ë“±)
    HISTOGRAM = "histogram"  # ë¶„í¬ê°’ (ì‘ë‹µ ì‹œê°„ ë“±)
    TIMER = "timer"          # ì‹œê°„ ì¸¡ì •

@dataclass
class Alert:
    """ì•Œë¦¼ ë©”ì‹œì§€"""
    id: str
    title: str
    message: str
    severity: AlertSeverity
    timestamp: datetime
    service: str
    tags: Dict[str, str] = field(default_factory=dict)
    resolved: bool = False
    resolved_at: Optional[datetime] = None
    
@dataclass 
class Metric:
    """ë©”íŠ¸ë¦­ ë°ì´í„°"""
    name: str
    value: float
    metric_type: MetricType
    timestamp: datetime
    tags: Dict[str, str] = field(default_factory=dict)
    unit: str = ""

@dataclass
class PerformanceSnapshot:
    """ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ·"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_mb: float
    disk_percent: float
    network_sent: int
    network_recv: int
    
    # ê±°ë˜ ê´€ë ¨ ë©”íŠ¸ë¦­
    active_positions: int = 0
    daily_trades: int = 0
    daily_profit: float = 0.0
    api_response_time: float = 0.0
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    uptime_seconds: float = 0.0
    error_rate: float = 0.0

class MonitoringService:
    """ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.alerts: Dict[str, Alert] = {}
        self.metrics: Dict[str, List[Metric]] = {}
        self.performance_history: List[PerformanceSnapshot] = []
        self.alert_channels: Dict[AlertChannel, List[Callable]] = {
            AlertChannel.LOG: [],
            AlertChannel.FILE: [],
            AlertChannel.EMAIL: [],
            AlertChannel.WEBHOOK: [],
            AlertChannel.SLACK: []
        }
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_active = False
        self.performance_interval = 30  # 30ì´ˆë§ˆë‹¤ ì„±ëŠ¥ ìˆ˜ì§‘
        self.metric_retention_hours = 24  # 24ì‹œê°„ ë©”íŠ¸ë¦­ ë³´ê´€
        self.alert_retention_hours = 168  # 7ì¼ê°„ ì•Œë¦¼ ë³´ê´€
        
        # ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            "cpu_percent": 80.0,
            "memory_percent": 85.0,
            "disk_percent": 90.0,
            "api_response_time": 5.0,
            "error_rate": 5.0
        }
        
        # ì•Œë¦¼ ì œí•œ (ì¤‘ë³µ ë°©ì§€)
        self.alert_cooldown = 300  # 5ë¶„ê°„ ê°™ì€ ì•Œë¦¼ ë°©ì§€
        self.last_alert_time: Dict[str, datetime] = {}
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹œê°„
        self.start_time = datetime.now()
        
        logger.info("âœ… ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def register_alert_handler(self, channel: AlertChannel, handler: Callable):
        """ì•Œë¦¼ í•¸ë“¤ëŸ¬ ë“±ë¡"""
        try:
            self.alert_channels[channel].append(handler)
            logger.info(f"ğŸ“¢ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ë“±ë¡: {channel.value}")
            
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ë“±ë¡ ì‹¤íŒ¨ ({channel.value}): {str(e)}")
    
    async def send_alert(
        self, 
        title: str, 
        message: str, 
        severity: AlertSeverity = AlertSeverity.INFO,
        service: str = "system",
        tags: Optional[Dict[str, str]] = None,
        channels: Optional[List[AlertChannel]] = None
    ) -> str:
        """ì•Œë¦¼ ë°œì†¡"""
        try:
            # ì•Œë¦¼ ID ìƒì„±
            alert_id = f"{service}_{int(time.time())}_{hash(title + message) % 1000}"
            
            # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ì¿¨ë‹¤ìš´ ì²´í¬)
            cooldown_key = f"{service}_{title}"
            now = datetime.now()
            
            if cooldown_key in self.last_alert_time:
                last_time = self.last_alert_time[cooldown_key]
                if (now - last_time).total_seconds() < self.alert_cooldown:
                    logger.debug(f"ì•Œë¦¼ ì¿¨ë‹¤ìš´ ì¤‘: {title}")
                    return alert_id
            
            self.last_alert_time[cooldown_key] = now
            
            # ì•Œë¦¼ ê°ì²´ ìƒì„±
            alert = Alert(
                id=alert_id,
                title=title,
                message=message,
                severity=severity,
                timestamp=now,
                service=service,
                tags=tags or {}
            )
            
            # ì•Œë¦¼ ì €ì¥
            self.alerts[alert_id] = alert
            
            # ì±„ë„ë³„ ì•Œë¦¼ ë°œì†¡
            if channels is None:
                channels = [AlertChannel.LOG, AlertChannel.FILE]  # ê¸°ë³¸ ì±„ë„
            
            for channel in channels:
                handlers = self.alert_channels.get(channel, [])
                for handler in handlers:
                    try:
                        await handler(alert)
                    except Exception as e:
                        logger.error(f"âŒ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜ ({channel.value}): {str(e)}")
            
            # ì‹¬ê°ë„ë³„ ë¡œê¹…
            log_msg = f"ğŸš¨ [{severity.value.upper()}] {title}: {message}"
            if severity == AlertSeverity.CRITICAL:
                logger.critical(log_msg)
            elif severity == AlertSeverity.ERROR:
                logger.error(log_msg)
            elif severity == AlertSeverity.WARNING:
                logger.warning(log_msg)
            else:
                logger.info(log_msg)
            
            return alert_id
            
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")
            return ""
    
    def add_metric(
        self, 
        name: str, 
        value: float, 
        metric_type: MetricType = MetricType.GAUGE,
        tags: Optional[Dict[str, str]] = None,
        unit: str = ""
    ):
        """ë©”íŠ¸ë¦­ ì¶”ê°€"""
        try:
            metric = Metric(
                name=name,
                value=value,
                metric_type=metric_type,
                timestamp=datetime.now(),
                tags=tags or {},
                unit=unit
            )
            
            if name not in self.metrics:
                self.metrics[name] = []
            
            self.metrics[name].append(metric)
            
            # ë©”íŠ¸ë¦­ ë³´ê´€ ê¸°ê°„ ê´€ë¦¬
            cutoff_time = datetime.now() - timedelta(hours=self.metric_retention_hours)
            self.metrics[name] = [
                m for m in self.metrics[name] 
                if m.timestamp >= cutoff_time
            ]
            
            logger.debug(f"ğŸ“Š ë©”íŠ¸ë¦­ ì¶”ê°€: {name} = {value} {unit}")
            
        except Exception as e:
            logger.error(f"âŒ ë©”íŠ¸ë¦­ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
    
    async def collect_system_performance(self) -> PerformanceSnapshot:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ìˆ˜ì§‘"""
        try:
            # ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            network = psutil.net_io_counters()
            
            # ê±°ë˜ ê´€ë ¨ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            active_positions = 0
            daily_trades = 0
            daily_profit = 0.0
            
            try:
                from ..services.trading_engine import trading_state
                active_positions = len(trading_state.positions)
                daily_trades = trading_state.daily_trades
                daily_profit = -trading_state.daily_loss  # ì†ì‹¤ì„ ìˆ˜ìµìœ¼ë¡œ ë³€í™˜
            except Exception:
                pass  # ê±°ë˜ ì—”ì§„ ì—°ê²° ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            
            # API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
            api_response_time = 0.0
            try:
                start_time = time.time()
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    async with session.get("https://api.upbit.com/v1/market/all", timeout=5) as response:
                        if response.status == 200:
                            api_response_time = (time.time() - start_time) * 1000  # ms
            except Exception:
                api_response_time = 9999.0  # ì—°ê²° ì‹¤íŒ¨ í‘œì‹œ
            
            # ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ· ìƒì„±
            snapshot = PerformanceSnapshot(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_mb=memory.used / 1024 / 1024,
                disk_percent=disk.percent,
                network_sent=network.bytes_sent,
                network_recv=network.bytes_recv,
                active_positions=active_positions,
                daily_trades=daily_trades,
                daily_profit=daily_profit,
                api_response_time=api_response_time,
                uptime_seconds=(datetime.now() - self.start_time).total_seconds(),
                error_rate=0.0  # TODO: ì‹¤ì œ ì˜¤ë¥˜ìœ¨ ê³„ì‚°
            )
            
            # ë©”íŠ¸ë¦­ìœ¼ë¡œ ì¶”ê°€
            self.add_metric("system.cpu_percent", cpu_percent, MetricType.GAUGE, unit="%")
            self.add_metric("system.memory_percent", memory.percent, MetricType.GAUGE, unit="%")
            self.add_metric("system.disk_percent", disk.percent, MetricType.GAUGE, unit="%")
            self.add_metric("trading.active_positions", active_positions, MetricType.GAUGE)
            self.add_metric("trading.daily_trades", daily_trades, MetricType.COUNTER)
            self.add_metric("trading.daily_profit", daily_profit, MetricType.GAUGE, unit="KRW")
            self.add_metric("api.response_time", api_response_time, MetricType.HISTOGRAM, unit="ms")
            
            # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.performance_history.append(snapshot)
            
            # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœê·¼ 1000ê°œ)
            if len(self.performance_history) > 1000:
                self.performance_history = self.performance_history[-1000:]
            
            # ì„ê³„ê°’ í™•ì¸ ë° ì•Œë¦¼
            await self._check_performance_thresholds(snapshot)
            
            return snapshot
            
        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ ìŠ¤ëƒ…ìƒ· ë°˜í™˜
            return PerformanceSnapshot(
                timestamp=datetime.now(),
                cpu_percent=0.0,
                memory_percent=0.0,
                memory_mb=0.0,
                disk_percent=0.0,
                network_sent=0,
                network_recv=0
            )
    
    async def _check_performance_thresholds(self, snapshot: PerformanceSnapshot):
        """ì„±ëŠ¥ ì„ê³„ê°’ í™•ì¸ ë° ì•Œë¦¼"""
        try:
            # CPU ì‚¬ìš©ë¥  í™•ì¸
            if snapshot.cpu_percent > self.thresholds["cpu_percent"]:
                await self.send_alert(
                    f"ë†’ì€ CPU ì‚¬ìš©ë¥ ",
                    f"CPU ì‚¬ìš©ë¥ ì´ {snapshot.cpu_percent:.1f}%ë¡œ ì„ê³„ê°’ {self.thresholds['cpu_percent']}%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                    AlertSeverity.WARNING,
                    "system"
                )
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
            if snapshot.memory_percent > self.thresholds["memory_percent"]:
                await self.send_alert(
                    f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
                    f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {snapshot.memory_percent:.1f}%ë¡œ ì„ê³„ê°’ {self.thresholds['memory_percent']}%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                    AlertSeverity.WARNING,
                    "system"
                )
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  í™•ì¸
            if snapshot.disk_percent > self.thresholds["disk_percent"]:
                await self.send_alert(
                    f"ë†’ì€ ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ",
                    f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ {snapshot.disk_percent:.1f}%ë¡œ ì„ê³„ê°’ {self.thresholds['disk_percent']}%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                    AlertSeverity.ERROR,
                    "system"
                )
            
            # API ì‘ë‹µ ì‹œê°„ í™•ì¸
            if snapshot.api_response_time > self.thresholds["api_response_time"] * 1000:  # msë¡œ ë³€í™˜
                await self.send_alert(
                    f"ëŠë¦° API ì‘ë‹µ",
                    f"ì—…ë¹„íŠ¸ API ì‘ë‹µ ì‹œê°„ì´ {snapshot.api_response_time:.0f}msë¡œ ì„ê³„ê°’ {self.thresholds['api_response_time']}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                    AlertSeverity.WARNING,
                    "upbit_api"
                )
                
        except Exception as e:
            logger.error(f"âŒ ì„ê³„ê°’ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
    
    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        logger.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        # ê¸°ë³¸ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ë“±ë¡
        await self._setup_default_alert_handlers()
        
        # ì„±ëŠ¥ ìˆ˜ì§‘ ë£¨í”„ ì‹œì‘
        performance_task = asyncio.create_task(self._performance_monitoring_loop())
        
        # ì•Œë¦¼ ì •ë¦¬ ë£¨í”„ ì‹œì‘
        cleanup_task = asyncio.create_task(self._cleanup_old_data_loop())
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì‹¤í–‰
        await asyncio.gather(performance_task, cleanup_task, return_exceptions=True)
    
    async def _performance_monitoring_loop(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                await self.collect_system_performance()
                await asyncio.sleep(self.performance_interval)
                
            except Exception as e:
                logger.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(self.performance_interval)
    
    async def _cleanup_old_data_loop(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ë£¨í”„"""
        while self.monitoring_active:
            try:
                await self._cleanup_old_alerts()
                await self._cleanup_old_metrics()
                await asyncio.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤ ì •ë¦¬
                
            except Exception as e:
                logger.error(f"âŒ ë°ì´í„° ì •ë¦¬ ë£¨í”„ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(3600)
    
    async def _cleanup_old_alerts(self):
        """ì˜¤ë˜ëœ ì•Œë¦¼ ì •ë¦¬"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=self.alert_retention_hours)
            
            old_alerts = [
                alert_id for alert_id, alert in self.alerts.items()
                if alert.timestamp < cutoff_time
            ]
            
            for alert_id in old_alerts:
                del self.alerts[alert_id]
            
            if old_alerts:
                logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ì•Œë¦¼ {len(old_alerts)}ê°œ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    async def _cleanup_old_metrics(self):
        """ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ ì •ë¦¬"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=self.metric_retention_hours)
            cleaned_count = 0
            
            for name in list(self.metrics.keys()):
                old_count = len(self.metrics[name])
                self.metrics[name] = [
                    m for m in self.metrics[name]
                    if m.timestamp >= cutoff_time
                ]
                cleaned_count += old_count - len(self.metrics[name])
                
                # ë¹ˆ ë©”íŠ¸ë¦­ ì œê±°
                if not self.metrics[name]:
                    del self.metrics[name]
            
            if cleaned_count > 0:
                logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ {cleaned_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ ë©”íŠ¸ë¦­ ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    async def _setup_default_alert_handlers(self):
        """ê¸°ë³¸ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        try:
            # íŒŒì¼ ì•Œë¦¼ í•¸ë“¤ëŸ¬
            async def file_alert_handler(alert: Alert):
                try:
                    alert_data = {
                        "id": alert.id,
                        "timestamp": alert.timestamp.isoformat(),
                        "title": alert.title,
                        "message": alert.message,
                        "severity": alert.severity.value,
                        "service": alert.service,
                        "tags": alert.tags
                    }
                    
                    os.makedirs("logs", exist_ok=True)
                    async with aiofiles.open("logs/alerts.jsonl", "a", encoding="utf-8") as f:
                        await f.write(json.dumps(alert_data, ensure_ascii=False) + "\n")
                        
                except Exception as e:
                    logger.error(f"âŒ íŒŒì¼ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜: {str(e)}")
            
            self.register_alert_handler(AlertChannel.FILE, file_alert_handler)
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    
    def get_alert_summary(self, hours: int = 24) -> Dict[str, Any]:
        """ì•Œë¦¼ ìš”ì•½ ì¡°íšŒ"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_alerts = [
                alert for alert in self.alerts.values()
                if alert.timestamp >= cutoff_time
            ]
            
            # ì‹¬ê°ë„ë³„ ì§‘ê³„
            severity_counts = {}
            for severity in AlertSeverity:
                severity_counts[severity.value] = len([
                    alert for alert in recent_alerts
                    if alert.severity == severity
                ])
            
            # ì„œë¹„ìŠ¤ë³„ ì§‘ê³„
            service_counts = {}
            for alert in recent_alerts:
                service_counts[alert.service] = service_counts.get(alert.service, 0) + 1
            
            return {
                "period_hours": hours,
                "total_alerts": len(recent_alerts),
                "by_severity": severity_counts,
                "by_service": service_counts,
                "recent_alerts": [
                    {
                        "id": alert.id,
                        "title": alert.title,
                        "message": alert.message,
                        "severity": alert.severity.value,
                        "service": alert.service,
                        "timestamp": alert.timestamp.isoformat()
                    }
                    for alert in sorted(recent_alerts, key=lambda x: x.timestamp, reverse=True)[:10]
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    def get_performance_summary(self, hours: int = 24) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_snapshots = [
                snapshot for snapshot in self.performance_history
                if snapshot.timestamp >= cutoff_time
            ]
            
            if not recent_snapshots:
                return {"error": "ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # í‰ê· ê°’ ê³„ì‚°
            avg_cpu = sum(s.cpu_percent for s in recent_snapshots) / len(recent_snapshots)
            avg_memory = sum(s.memory_percent for s in recent_snapshots) / len(recent_snapshots)
            avg_api_time = sum(s.api_response_time for s in recent_snapshots) / len(recent_snapshots)
            
            # ìµœì‹  ë°ì´í„°
            latest = recent_snapshots[-1]
            
            return {
                "period_hours": hours,
                "snapshot_count": len(recent_snapshots),
                "averages": {
                    "cpu_percent": round(avg_cpu, 2),
                    "memory_percent": round(avg_memory, 2),
                    "api_response_time": round(avg_api_time, 2)
                },
                "latest": {
                    "timestamp": latest.timestamp.isoformat(),
                    "cpu_percent": latest.cpu_percent,
                    "memory_percent": latest.memory_percent,
                    "memory_mb": round(latest.memory_mb, 1),
                    "disk_percent": latest.disk_percent,
                    "active_positions": latest.active_positions,
                    "daily_trades": latest.daily_trades,
                    "daily_profit": latest.daily_profit,
                    "api_response_time": latest.api_response_time,
                    "uptime_hours": round(latest.uptime_seconds / 3600, 2)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    def get_metrics_data(self, metric_name: str, hours: int = 24) -> Dict[str, Any]:
        """íŠ¹ì • ë©”íŠ¸ë¦­ ë°ì´í„° ì¡°íšŒ"""
        try:
            if metric_name not in self.metrics:
                return {"error": f"ë©”íŠ¸ë¦­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metric_name}"}
            
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_metrics = [
                metric for metric in self.metrics[metric_name]
                if metric.timestamp >= cutoff_time
            ]
            
            if not recent_metrics:
                return {"error": "ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # í†µê³„ ê³„ì‚°
            values = [m.value for m in recent_metrics]
            
            return {
                "metric_name": metric_name,
                "period_hours": hours,
                "data_points": len(recent_metrics),
                "statistics": {
                    "min": min(values),
                    "max": max(values),
                    "avg": sum(values) / len(values),
                    "latest": values[-1]
                },
                "unit": recent_metrics[-1].unit if recent_metrics else "",
                "data": [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "value": m.value,
                        "tags": m.tags
                    }
                    for m in recent_metrics[-100:]  # ìµœê·¼ 100ê°œë§Œ
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ ë©”íŠ¸ë¦­ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    async def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        logger.info("ğŸ›‘ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def update_thresholds(self, new_thresholds: Dict[str, float]):
        """ì„ê³„ê°’ ì—…ë°ì´íŠ¸"""
        try:
            self.thresholds.update(new_thresholds)
            logger.info(f"âš™ï¸ ì„ê³„ê°’ ì—…ë°ì´íŠ¸: {new_thresholds}")
            
        except Exception as e:
            logger.error(f"âŒ ì„ê³„ê°’ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

# ì „ì—­ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
monitoring_service = MonitoringService()