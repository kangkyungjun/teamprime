"""
ë¶„ì„ ë° ë¦¬í¬íŒ… API ì—”ë“œí¬ì¸íŠ¸
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë¶„ì„
- ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„  
- ì§€ì¶œ íŒ¨í„´ ë¶„ì„
- ìˆ˜ìµ ì˜ˆì¸¡ ë° íŠ¸ë Œë“œ
- ë¦¬í¬íŠ¸ ìƒì„±
"""

import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List
from fastapi import APIRouter, Request, Depends, HTTPException, Query
from sqlalchemy import text, func
import calendar
import json
from collections import defaultdict

logger = logging.getLogger(__name__)
router = APIRouter()

async def get_current_user_from_request(request: Request):
    """ìš”ì²­ì—ì„œ í˜„ì¬ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ"""
    from core.auth.middleware import get_current_user
    return await get_current_user(request)

@router.get("/api/analytics/business-performance")
async def get_business_performance(
    request: Request,
    period: str = Query("12months", description="ë¶„ì„ ê¸°ê°„: 3months, 6months, 12months, 2years"),
    user: Dict = Depends(get_current_user_from_request)
):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë¶„ì„ - ì›”ë³„/ë¶„ê¸°ë³„ ìˆ˜ìµ ë¶„ì„"""
    
    if not user:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    try:
        from core.database.mysql_connection import get_mysql_connection
        
        # ê¸°ê°„ ì„¤ì •
        period_months = {
            "3months": 3,
            "6months": 6, 
            "12months": 12,
            "2years": 24
        }
        
        months = period_months.get(period, 12)
        start_date = datetime.now() - timedelta(days=months * 30)
        
        async with get_mysql_connection() as connection:
            
            # ì›”ë³„ ìˆ˜ìµ ë¶„ì„
            income_query = text("""
                SELECT 
                    DATE_FORMAT(income_date, '%Y-%m') as month,
                    category,
                    COUNT(*) as count,
                    SUM(amount) as total_amount,
                    SUM(tax) as total_tax,
                    SUM(amount - tax) as net_amount
                FROM incomes 
                WHERE income_date >= :start_date
                GROUP BY DATE_FORMAT(income_date, '%Y-%m'), category
                ORDER BY month DESC, category
            """)
            
            income_result = await connection.execute(income_query, {"start_date": start_date})
            income_data = income_result.fetchall()
            
            # ì›”ë³„ ì§€ì¶œ ë¶„ì„
            expense_query = text("""
                SELECT 
                    DATE_FORMAT(expense_date, '%Y-%m') as month,
                    category,
                    status,
                    COUNT(*) as count,
                    SUM(amount) as total_amount
                FROM expenses 
                WHERE expense_date >= :start_date
                GROUP BY DATE_FORMAT(expense_date, '%Y-%m'), category, status
                ORDER BY month DESC, category
            """)
            
            expense_result = await connection.execute(expense_query, {"start_date": start_date})
            expense_data = expense_result.fetchall()
            
            # ì—…ë¬´ ì™„ë£Œ ë¶„ì„ (ìƒì‚°ì„± ì§€í‘œ)
            task_query = text("""
                SELECT 
                    DATE_FORMAT(updated_at, '%Y-%m') as month,
                    category,
                    status,
                    priority,
                    COUNT(*) as count,
                    AVG(estimated_hours) as avg_hours
                FROM tasks 
                WHERE updated_at >= :start_date
                GROUP BY DATE_FORMAT(updated_at, '%Y-%m'), category, status, priority
                ORDER BY month DESC
            """)
            
            task_result = await connection.execute(task_query, {"start_date": start_date})
            task_data = task_result.fetchall()
            
        # ë°ì´í„° ê°€ê³µ
        monthly_summary = defaultdict(lambda: {
            'income': {'total': 0, 'tax': 0, 'net': 0, 'categories': {}},
            'expense': {'total': 0, 'approved': 0, 'categories': {}},
            'tasks': {'total': 0, 'completed': 0, 'productivity': 0}
        })
        
        # ìˆ˜ìµ ë°ì´í„° ê°€ê³µ
        for row in income_data:
            month = row.month
            category = row.category
            monthly_summary[month]['income']['total'] += float(row.total_amount)
            monthly_summary[month]['income']['tax'] += float(row.total_tax or 0)
            monthly_summary[month]['income']['net'] += float(row.net_amount or 0)
            
            if category not in monthly_summary[month]['income']['categories']:
                monthly_summary[month]['income']['categories'][category] = 0
            monthly_summary[month]['income']['categories'][category] += float(row.total_amount)
        
        # ì§€ì¶œ ë°ì´í„° ê°€ê³µ
        for row in expense_data:
            month = row.month
            category = row.category
            status = row.status
            amount = float(row.total_amount)
            
            monthly_summary[month]['expense']['total'] += amount
            if status == 'approved':
                monthly_summary[month]['expense']['approved'] += amount
                
            if category not in monthly_summary[month]['expense']['categories']:
                monthly_summary[month]['expense']['categories'][category] = 0
            monthly_summary[month]['expense']['categories'][category] += amount
        
        # ì—…ë¬´ ë°ì´í„° ê°€ê³µ
        for row in task_data:
            month = row.month
            status = row.status
            count = row.count
            
            monthly_summary[month]['tasks']['total'] += count
            if status == 'completed':
                monthly_summary[month]['tasks']['completed'] += count
        
        # ìƒì‚°ì„± ê³„ì‚°
        for month in monthly_summary:
            total_tasks = monthly_summary[month]['tasks']['total']
            completed_tasks = monthly_summary[month]['tasks']['completed']
            if total_tasks > 0:
                monthly_summary[month]['tasks']['productivity'] = round((completed_tasks / total_tasks) * 100, 2)
        
        # ì›”ë³„ ì •ë ¬ ë° ìµœì¢… ë°ì´í„° êµ¬ì„±
        sorted_months = sorted(monthly_summary.keys(), reverse=True)
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        revenue_trend = []
        profit_trend = []
        productivity_trend = []
        
        for month in sorted_months:
            data = monthly_summary[month]
            revenue_trend.append({
                'month': month,
                'revenue': data['income']['total'],
                'expense': data['expense']['approved'],
                'profit': data['income']['net'] - data['expense']['approved']
            })
            
            productivity_trend.append({
                'month': month,
                'productivity': data['tasks']['productivity']
            })
        
        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        current_month = datetime.now().strftime('%Y-%m')
        previous_month = (datetime.now() - timedelta(days=32)).strftime('%Y-%m')
        
        current_profit = 0
        previous_profit = 0
        
        if current_month in monthly_summary:
            current_data = monthly_summary[current_month]
            current_profit = current_data['income']['net'] - current_data['expense']['approved']
            
        if previous_month in monthly_summary:
            previous_data = monthly_summary[previous_month]
            previous_profit = previous_data['income']['net'] - previous_data['expense']['approved']
        
        profit_growth = 0
        if previous_profit != 0:
            profit_growth = round(((current_profit - previous_profit) / abs(previous_profit)) * 100, 2)
        
        return {
            "success": True,
            "period": period,
            "analysis_period": f"{start_date.strftime('%Y-%m')} ~ {datetime.now().strftime('%Y-%m')}",
            "summary": {
                "total_months": len(sorted_months),
                "current_month_profit": current_profit,
                "previous_month_profit": previous_profit,
                "profit_growth_rate": profit_growth,
                "avg_monthly_revenue": sum(monthly_summary[m]['income']['total'] for m in monthly_summary) / len(monthly_summary) if monthly_summary else 0,
                "avg_monthly_expense": sum(monthly_summary[m]['expense']['approved'] for m in monthly_summary) / len(monthly_summary) if monthly_summary else 0,
                "avg_productivity": sum(monthly_summary[m]['tasks']['productivity'] for m in monthly_summary) / len(monthly_summary) if monthly_summary else 0
            },
            "monthly_data": dict(monthly_summary),
            "trends": {
                "revenue_profit": revenue_trend,
                "productivity": productivity_trend
            },
            "top_income_categories": get_top_categories([row.category for row in income_data]),
            "top_expense_categories": get_top_categories([row.category for row in expense_data])
        }
        
    except Exception as e:
        logger.error(f"ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/api/analytics/task-efficiency")
async def get_task_efficiency_analysis(
    request: Request,
    period: str = Query("30days", description="ë¶„ì„ ê¸°ê°„: 7days, 30days, 90days"),
    user: Dict = Depends(get_current_user_from_request)
):
    """ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„ - ì™„ë£Œìœ¨, ì§€ì—°ë¥ , ìƒì‚°ì„± ì§€í‘œ"""
    
    if not user:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    try:
        from core.database.mysql_connection import get_mysql_connection
        
        # ê¸°ê°„ ì„¤ì •
        period_days = {
            "7days": 7,
            "30days": 30,
            "90days": 90
        }
        
        days = period_days.get(period, 30)
        start_date = datetime.now() - timedelta(days=days)
        
        async with get_mysql_connection() as connection:
            
            # ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„ ì¿¼ë¦¬
            efficiency_query = text("""
                SELECT 
                    assignee_id,
                    category,
                    priority,
                    status,
                    estimated_hours,
                    start_date,
                    due_date,
                    created_at,
                    updated_at,
                    CASE 
                        WHEN due_date IS NOT NULL AND status = 'completed' AND updated_at > due_date 
                        THEN 1 ELSE 0 
                    END as is_delayed,
                    CASE 
                        WHEN status = 'completed' 
                        THEN DATEDIFF(updated_at, created_at) 
                        ELSE NULL 
                    END as completion_days
                FROM tasks 
                WHERE created_at >= :start_date
                ORDER BY created_at DESC
            """)
            
            result = await connection.execute(efficiency_query, {"start_date": start_date})
            task_data = result.fetchall()
            
            # ì‚¬ìš©ìë³„ ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„
            user_efficiency_query = text("""
                SELECT 
                    u.id as user_id,
                    u.username,
                    u.role,
                    COUNT(t.id) as total_tasks,
                    SUM(CASE WHEN t.status = 'completed' THEN 1 ELSE 0 END) as completed_tasks,
                    SUM(CASE WHEN t.due_date IS NOT NULL AND t.status = 'completed' 
                             AND t.updated_at > t.due_date THEN 1 ELSE 0 END) as delayed_tasks,
                    AVG(CASE WHEN t.status = 'completed' 
                             THEN DATEDIFF(t.updated_at, t.created_at) ELSE NULL END) as avg_completion_days,
                    SUM(t.estimated_hours) as total_estimated_hours
                FROM users u
                LEFT JOIN tasks t ON u.id = t.assignee_id AND t.created_at >= :start_date
                GROUP BY u.id, u.username, u.role
                HAVING COUNT(t.id) > 0
                ORDER BY completed_tasks DESC
            """)
            
            user_result = await connection.execute(user_efficiency_query, {"start_date": start_date})
            user_data = user_result.fetchall()
        
        # ì „ì²´ í†µê³„ ê³„ì‚°
        total_tasks = len(task_data)
        completed_tasks = sum(1 for task in task_data if task.status == 'completed')
        delayed_tasks = sum(task.is_delayed for task in task_data)
        
        completion_rate = round((completed_tasks / total_tasks) * 100, 2) if total_tasks > 0 else 0
        delay_rate = round((delayed_tasks / total_tasks) * 100, 2) if total_tasks > 0 else 0
        
        # í‰ê·  ì™„ë£Œ ì‹œê°„
        completion_times = [task.completion_days for task in task_data if task.completion_days is not None]
        avg_completion_time = round(sum(completion_times) / len(completion_times), 1) if completion_times else 0
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        category_stats = defaultdict(lambda: {'total': 0, 'completed': 0, 'delayed': 0})
        for task in task_data:
            category = task.category
            category_stats[category]['total'] += 1
            if task.status == 'completed':
                category_stats[category]['completed'] += 1
            if task.is_delayed:
                category_stats[category]['delayed'] += 1
        
        # ì¹´í…Œê³ ë¦¬ë³„ íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
        category_efficiency = {}
        for category, stats in category_stats.items():
            if stats['total'] > 0:
                completion_rate = (stats['completed'] / stats['total']) * 100
                delay_rate = (stats['delayed'] / stats['total']) * 100
                efficiency_score = max(0, completion_rate - delay_rate)  # ì™„ë£Œìœ¨ - ì§€ì—°ë¥ 
                category_efficiency[category] = {
                    'total_tasks': stats['total'],
                    'completion_rate': round(completion_rate, 2),
                    'delay_rate': round(delay_rate, 2),
                    'efficiency_score': round(efficiency_score, 2)
                }
        
        # ìš°ì„ ìˆœìœ„ë³„ ë¶„ì„
        priority_stats = defaultdict(lambda: {'total': 0, 'completed': 0, 'delayed': 0})
        for task in task_data:
            priority = task.priority
            priority_stats[priority]['total'] += 1
            if task.status == 'completed':
                priority_stats[priority]['completed'] += 1
            if task.is_delayed:
                priority_stats[priority]['delayed'] += 1
        
        # ì‚¬ìš©ìë³„ íš¨ìœ¨ì„± ë°ì´í„° ê°€ê³µ
        user_efficiency = []
        for user in user_data:
            total = user.total_tasks
            completed = user.completed_tasks
            delayed = user.delayed_tasks
            
            completion_rate = round((completed / total) * 100, 2) if total > 0 else 0
            delay_rate = round((delayed / total) * 100, 2) if total > 0 else 0
            efficiency_score = max(0, completion_rate - delay_rate)
            
            user_efficiency.append({
                'user_id': user.user_id,
                'username': user.username,
                'role': user.role,
                'total_tasks': total,
                'completed_tasks': completed,
                'delayed_tasks': delayed,
                'completion_rate': completion_rate,
                'delay_rate': delay_rate,
                'efficiency_score': round(efficiency_score, 2),
                'avg_completion_days': round(float(user.avg_completion_days), 1) if user.avg_completion_days else 0,
                'total_estimated_hours': float(user.total_estimated_hours) if user.total_estimated_hours else 0
            })
        
        # íš¨ìœ¨ì„± ì ìˆ˜ë³„ ì •ë ¬
        user_efficiency.sort(key=lambda x: x['efficiency_score'], reverse=True)
        
        return {
            "success": True,
            "period": period,
            "analysis_period": f"{start_date.strftime('%Y-%m-%d')} ~ {datetime.now().strftime('%Y-%m-%d')}",
            "overall_stats": {
                "total_tasks": total_tasks,
                "completed_tasks": completed_tasks,
                "delayed_tasks": delayed_tasks,
                "completion_rate": completion_rate,
                "delay_rate": delay_rate,
                "avg_completion_time": avg_completion_time,
                "productivity_score": round(max(0, completion_rate - delay_rate), 2)
            },
            "category_efficiency": category_efficiency,
            "priority_analysis": {
                priority: {
                    'total': stats['total'],
                    'completion_rate': round((stats['completed'] / stats['total']) * 100, 2) if stats['total'] > 0 else 0,
                    'delay_rate': round((stats['delayed'] / stats['total']) * 100, 2) if stats['total'] > 0 else 0
                }
                for priority, stats in priority_stats.items()
            },
            "user_efficiency": user_efficiency,
            "insights": generate_efficiency_insights(category_efficiency, user_efficiency, completion_rate, delay_rate)
        }
        
    except Exception as e:
        logger.error(f"ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/api/analytics/expense-patterns")
async def get_expense_pattern_analysis(
    request: Request,
    period: str = Query("6months", description="ë¶„ì„ ê¸°ê°„: 3months, 6months, 12months"),
    user: Dict = Depends(get_current_user_from_request)
):
    """ì§€ì¶œ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆì‚° ê´€ë¦¬"""
    
    if not user:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    try:
        from core.database.mysql_connection import get_mysql_connection
        
        # ê¸°ê°„ ì„¤ì •
        period_months = {"3months": 3, "6months": 6, "12months": 12}
        months = period_months.get(period, 6)
        start_date = datetime.now() - timedelta(days=months * 30)
        
        async with get_mysql_connection() as connection:
            
            # ì§€ì¶œ íŒ¨í„´ ë¶„ì„
            expense_pattern_query = text("""
                SELECT 
                    DATE_FORMAT(expense_date, '%Y-%m') as month,
                    category,
                    status,
                    COUNT(*) as transaction_count,
                    SUM(amount) as total_amount,
                    AVG(amount) as avg_amount,
                    MIN(amount) as min_amount,
                    MAX(amount) as max_amount,
                    DAYOFWEEK(expense_date) as day_of_week
                FROM expenses 
                WHERE expense_date >= :start_date
                GROUP BY DATE_FORMAT(expense_date, '%Y-%m'), category, status
                ORDER BY month DESC, total_amount DESC
            """)
            
            result = await connection.execute(expense_pattern_query, {"start_date": start_date})
            expense_data = result.fetchall()
            
            # ìŠ¹ì¸ë¥  ë¶„ì„
            approval_query = text("""
                SELECT 
                    category,
                    COUNT(*) as total_requests,
                    SUM(CASE WHEN status = 'approved' THEN 1 ELSE 0 END) as approved_count,
                    SUM(CASE WHEN status = 'rejected' THEN 1 ELSE 0 END) as rejected_count,
                    AVG(amount) as avg_amount,
                    SUM(CASE WHEN status = 'approved' THEN amount ELSE 0 END) as approved_amount
                FROM expenses 
                WHERE expense_date >= :start_date
                GROUP BY category
                ORDER BY total_requests DESC
            """)
            
            approval_result = await connection.execute(approval_query, {"start_date": start_date})
            approval_data = approval_result.fetchall()
            
            # ì¼ë³„ ì§€ì¶œ íŒ¨í„´
            daily_pattern_query = text("""
                SELECT 
                    DAYOFWEEK(expense_date) as day_of_week,
                    COUNT(*) as transaction_count,
                    SUM(amount) as total_amount,
                    AVG(amount) as avg_amount
                FROM expenses 
                WHERE expense_date >= :start_date AND status = 'approved'
                GROUP BY DAYOFWEEK(expense_date)
                ORDER BY day_of_week
            """)
            
            daily_result = await connection.execute(daily_pattern_query, {"start_date": start_date})
            daily_data = daily_result.fetchall()
        
        # ì›”ë³„ ì§€ì¶œ íŒ¨í„´ ë¶„ì„
        monthly_patterns = defaultdict(lambda: {'total': 0, 'categories': {}, 'approved': 0})
        
        for row in expense_data:
            month = row.month
            category = row.category
            status = row.status
            amount = float(row.total_amount)
            
            monthly_patterns[month]['total'] += amount
            if status == 'approved':
                monthly_patterns[month]['approved'] += amount
                
            if category not in monthly_patterns[month]['categories']:
                monthly_patterns[month]['categories'][category] = 0
            monthly_patterns[month]['categories'][category] += amount
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìŠ¹ì¸ë¥  ë° íŒ¨í„´
        category_analysis = {}
        for row in approval_data:
            category = row.category
            total_requests = row.total_requests
            approved_count = row.approved_count
            rejected_count = row.rejected_count
            
            approval_rate = round((approved_count / total_requests) * 100, 2) if total_requests > 0 else 0
            rejection_rate = round((rejected_count / total_requests) * 100, 2) if total_requests > 0 else 0
            
            category_analysis[category] = {
                'total_requests': total_requests,
                'approval_rate': approval_rate,
                'rejection_rate': rejection_rate,
                'avg_amount': round(float(row.avg_amount), 2),
                'approved_amount': float(row.approved_amount),
                'risk_level': 'high' if approval_rate < 70 else ('medium' if approval_rate < 85 else 'low')
            }
        
        # ìš”ì¼ë³„ ì§€ì¶œ íŒ¨í„´
        days_of_week = ['ì¼ìš”ì¼', 'ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼']
        daily_patterns = {}
        
        for row in daily_data:
            day_index = row.day_of_week - 1  # MySQL DAYOFWEEKëŠ” 1ë¶€í„° ì‹œì‘
            day_name = days_of_week[day_index]
            daily_patterns[day_name] = {
                'transaction_count': row.transaction_count,
                'total_amount': float(row.total_amount),
                'avg_amount': round(float(row.avg_amount), 2)
            }
        
        # ì˜ˆì‚° ì¶”ì²œ ê³„ì‚°
        total_months = len(monthly_patterns)
        avg_monthly_expense = sum(monthly_patterns[m]['approved'] for m in monthly_patterns) / total_months if total_months > 0 else 0
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‚° ì¶”ì²œ
        category_budgets = {}
        for category, analysis in category_analysis.items():
            monthly_avg = analysis['approved_amount'] / total_months if total_months > 0 else 0
            # ìŠ¹ì¸ë¥ ì„ ê³ ë ¤í•œ ë²„í¼ ì¶”ê°€
            buffer_rate = 1.2 if analysis['approval_rate'] > 90 else 1.5
            recommended_budget = monthly_avg * buffer_rate
            
            category_budgets[category] = {
                'current_monthly_avg': round(monthly_avg, 2),
                'recommended_budget': round(recommended_budget, 2),
                'buffer_rate': buffer_rate,
                'confidence': 'high' if analysis['total_requests'] >= 10 else 'medium'
            }
        
        # ì§€ì¶œ íŠ¸ë Œë“œ ì˜ˆì¸¡
        sorted_months = sorted(monthly_patterns.keys())
        monthly_trend = []
        for month in sorted_months:
            monthly_trend.append({
                'month': month,
                'total_expense': monthly_patterns[month]['approved'],
                'categories': monthly_patterns[month]['categories']
            })
        
        # ì´ìƒ ì§€ì¶œ ê°ì§€ (í‰ê· ì˜ 150% ì´ìƒì¸ ê²½ìš°)
        anomalies = []
        if len(monthly_trend) >= 3:
            recent_avg = sum(t['total_expense'] for t in monthly_trend[-3:]) / 3
            for trend in monthly_trend:
                if trend['total_expense'] > recent_avg * 1.5:
                    anomalies.append({
                        'month': trend['month'],
                        'amount': trend['total_expense'],
                        'deviation': round(((trend['total_expense'] - recent_avg) / recent_avg) * 100, 2)
                    })
        
        return {
            "success": True,
            "period": period,
            "analysis_period": f"{start_date.strftime('%Y-%m')} ~ {datetime.now().strftime('%Y-%m')}",
            "summary": {
                "total_months_analyzed": total_months,
                "avg_monthly_expense": round(avg_monthly_expense, 2),
                "total_approved_expense": sum(monthly_patterns[m]['approved'] for m in monthly_patterns),
                "most_expensive_category": max(category_analysis.items(), key=lambda x: x[1]['approved_amount'])[0] if category_analysis else None,
                "highest_risk_category": min(category_analysis.items(), key=lambda x: x[1]['approval_rate'])[0] if category_analysis else None
            },
            "monthly_patterns": dict(monthly_patterns),
            "category_analysis": category_analysis,
            "daily_patterns": daily_patterns,
            "budget_recommendations": category_budgets,
            "expense_trends": monthly_trend,
            "anomalies": anomalies,
            "insights": generate_expense_insights(category_analysis, monthly_patterns, daily_patterns)
        }
        
    except Exception as e:
        logger.error(f"ì§€ì¶œ íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def get_top_categories(category_list, limit=5):
    """ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
    from collections import Counter
    category_counts = Counter(category_list)
    return [{"category": cat, "count": count} for cat, count in category_counts.most_common(limit)]

def generate_efficiency_insights(category_efficiency, user_efficiency, completion_rate, delay_rate):
    """ì—…ë¬´ íš¨ìœ¨ì„± ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []
    
    # ì „ì²´ íš¨ìœ¨ì„± í‰ê°€
    if completion_rate >= 80:
        insights.append("âœ… ì „ì²´ ì—…ë¬´ ì™„ë£Œìœ¨ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤ (80% ì´ìƒ)")
    elif completion_rate >= 60:
        insights.append("âš ï¸ ì—…ë¬´ ì™„ë£Œìœ¨ì´ ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
    else:
        insights.append("ğŸš¨ ì—…ë¬´ ì™„ë£Œìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
    
    # ì§€ì—°ë¥  í‰ê°€
    if delay_rate <= 10:
        insights.append("âœ… ì—…ë¬´ ì§€ì—°ë¥ ì´ ë‚®ì•„ ì¼ì • ê´€ë¦¬ê°€ ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤")
    elif delay_rate <= 20:
        insights.append("âš ï¸ ì—…ë¬´ ì§€ì—°ë¥ ì´ ë‹¤ì†Œ ë†’ìŠµë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ ê°œì„ ì„ ê¶Œì¥í•©ë‹ˆë‹¤")
    else:
        insights.append("ğŸš¨ ì—…ë¬´ ì§€ì—°ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ ì‹œìŠ¤í…œì„ ì ê²€í•´ì£¼ì„¸ìš”")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì¸ì‚¬ì´íŠ¸
    if category_efficiency:
        best_category = max(category_efficiency.items(), key=lambda x: x[1]['efficiency_score'])
        worst_category = min(category_efficiency.items(), key=lambda x: x[1]['efficiency_score'])
        
        insights.append(f"ğŸ† ê°€ì¥ íš¨ìœ¨ì ì¸ ì—…ë¬´ ë¶„ì•¼: {best_category[0]} ({best_category[1]['efficiency_score']}ì )")
        insights.append(f"ğŸ“‰ ê°œì„ ì´ í•„ìš”í•œ ì—…ë¬´ ë¶„ì•¼: {worst_category[0]} ({worst_category[1]['efficiency_score']}ì )")
    
    # ì‚¬ìš©ìë³„ ì¸ì‚¬ì´íŠ¸
    if user_efficiency and len(user_efficiency) > 1:
        top_performer = user_efficiency[0]
        insights.append(f"ğŸŒŸ ìµœê³  ì„±ê³¼ì: {top_performer['username']} (íš¨ìœ¨ì„± ì ìˆ˜: {top_performer['efficiency_score']}ì )")
    
    return insights

@router.get("/api/analytics/revenue-prediction")
async def get_revenue_prediction(
    request: Request,
    periods: int = Query(6, description="ì˜ˆì¸¡í•  ê¸°ê°„ (ê°œì›”)", ge=1, le=12),
    user: Dict = Depends(get_current_user_from_request)
):
    """ìˆ˜ìµ ì˜ˆì¸¡ ë° íŠ¸ë Œë“œ ë¶„ì„"""
    
    if not user:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    try:
        from core.database.mysql_connection import get_mysql_connection
        from core.services.prediction_service import prediction_service
        
        # ê³¼ê±° 24ê°œì›” ë°ì´í„° ìˆ˜ì§‘ (ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°)
        start_date = datetime.now() - timedelta(days=24 * 30)
        
        async with get_mysql_connection() as connection:
            
            # ì›”ë³„ ìˆ˜ìµ/ì§€ì¶œ/ì´ìµ ë°ì´í„°
            revenue_query = text("""
                SELECT 
                    DATE_FORMAT(income_date, '%Y-%m') as month,
                    SUM(amount - IFNULL(tax, 0)) as income,
                    0 as expense,
                    SUM(amount - IFNULL(tax, 0)) as profit
                FROM incomes 
                WHERE income_date >= :start_date
                GROUP BY DATE_FORMAT(income_date, '%Y-%m')
                
                UNION ALL
                
                SELECT 
                    DATE_FORMAT(expense_date, '%Y-%m') as month,
                    0 as income,
                    SUM(amount) as expense,
                    -SUM(amount) as profit
                FROM expenses 
                WHERE expense_date >= :start_date AND status = 'approved'
                GROUP BY DATE_FORMAT(expense_date, '%Y-%m')
                
                ORDER BY month
            """)
            
            result = await connection.execute(revenue_query, {"start_date": start_date})
            raw_data = result.fetchall()
        
        # ë°ì´í„° ì§‘ê³„ (ì›”ë³„ë¡œ ìˆ˜ìµê³¼ ì§€ì¶œ í•©ê³„)
        monthly_data = defaultdict(lambda: {'income': 0, 'expense': 0, 'profit': 0})
        
        for row in raw_data:
            month = row.month
            monthly_data[month]['income'] += float(row.income)
            monthly_data[month]['expense'] += float(row.expense)
            monthly_data[month]['profit'] += float(row.profit)
        
        # ìµœì¢… ì›”ë³„ ìˆœì´ìµ ê³„ì‚°
        historical_data = []
        for month in sorted(monthly_data.keys()):
            data = monthly_data[month]
            net_profit = data['income'] - data['expense']
            historical_data.append({
                'month': month,
                'income': data['income'],
                'expense': data['expense'], 
                'profit': net_profit
            })
        
        if len(historical_data) < 3:
            return {
                "success": False,
                "message": "ì˜ˆì¸¡ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 3ê°œì›”ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "data_points": len(historical_data)
            }
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions, trend_analysis = prediction_service.predict_revenue_trends(
            historical_data, periods
        )
        
        # í˜„ì¬ ë°ì´í„° ìš”ì•½
        current_summary = {
            'total_months': len(historical_data),
            'avg_monthly_income': sum(d['income'] for d in historical_data) / len(historical_data),
            'avg_monthly_expense': sum(d['expense'] for d in historical_data) / len(historical_data),
            'avg_monthly_profit': sum(d['profit'] for d in historical_data) / len(historical_data),
            'last_month_profit': historical_data[-1]['profit'] if historical_data else 0
        }
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = prediction_service.generate_business_insights(
            predictions, trend_analysis, {
                'profits': [d['profit'] for d in historical_data]
            }
        )
        
        # ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€ (ê³¼ê±° ë°ì´í„°ë¡œ ê²€ì¦)
        accuracy_score = calculate_prediction_accuracy(historical_data) if len(historical_data) >= 6 else 0
        
        # ë¦¬ìŠ¤í¬ ë¶„ì„
        risk_analysis = analyze_prediction_risks(predictions, trend_analysis)
        
        return {
            "success": True,
            "prediction_period": f"{periods}ê°œì›”",
            "model_info": {
                "type": "Linear Regression with Seasonality",
                "data_points_used": len(historical_data),
                "accuracy_score": round(accuracy_score, 2),
                "confidence_level": "95%"
            },
            "historical_summary": current_summary,
            "trend_analysis": {
                "direction": trend_analysis.trend_direction,
                "strength": round(trend_analysis.trend_strength, 2),
                "growth_rate": round(trend_analysis.growth_rate, 2),
                "volatility": round(trend_analysis.volatility, 2),
                "seasonality_detected": trend_analysis.seasonality_detected,
                "seasonal_pattern": trend_analysis.seasonal_pattern
            },
            "predictions": [
                {
                    "date": pred.date,
                    "predicted_income": round(pred.predicted_income, 2),
                    "predicted_expense": round(pred.predicted_expense, 2),
                    "predicted_profit": round(pred.predicted_profit, 2),
                    "confidence_lower": round(pred.confidence_lower, 2),
                    "confidence_upper": round(pred.confidence_upper, 2),
                    "trend_strength": round(pred.trend_strength, 2)
                }
                for pred in predictions
            ],
            "risk_analysis": risk_analysis,
            "business_insights": insights,
            "recommendations": generate_strategic_recommendations(
                trend_analysis, predictions, current_summary
            )
        }
        
    except Exception as e:
        logger.error(f"ìˆ˜ìµ ì˜ˆì¸¡ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def calculate_prediction_accuracy(historical_data: List[Dict]) -> float:
    """ì˜ˆì¸¡ ëª¨ë¸ì˜ ì •í™•ë„ ê³„ì‚° (ê³¼ê±° ë°ì´í„°ë¡œ ê²€ì¦)"""
    
    if len(historical_data) < 6:
        return 0
    
    # ê³¼ê±° ë°ì´í„°ì˜ í›„ë°˜ë¶€ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©
    train_size = len(historical_data) // 2
    train_data = historical_data[:train_size]
    test_data = historical_data[train_size:]
    
    try:
        from core.services.prediction_service import prediction_service
        
        # í›ˆë ¨ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        predictions, _ = prediction_service.predict_revenue_trends(train_data, len(test_data))
        
        # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
        actual_profits = [d['profit'] for d in test_data]
        predicted_profits = [p.predicted_profit for p in predictions[:len(actual_profits)]]
        
        # MAPE (Mean Absolute Percentage Error) ê³„ì‚°
        mape_errors = []
        for actual, predicted in zip(actual_profits, predicted_profits):
            if actual != 0:
                mape_errors.append(abs((actual - predicted) / actual))
        
        if mape_errors:
            mape = sum(mape_errors) / len(mape_errors)
            accuracy = max(0, (1 - mape) * 100)  # MAPEë¥¼ ì •í™•ë„ë¡œ ë³€í™˜
        else:
            accuracy = 0
        
        return min(100, accuracy)  # ìµœëŒ€ 100%
        
    except Exception as e:
        logger.error(f"ì •í™•ë„ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return 0

def analyze_prediction_risks(predictions: List, trend_analysis) -> Dict:
    """ì˜ˆì¸¡ ë¦¬ìŠ¤í¬ ë¶„ì„"""
    
    if not predictions:
        return {"overall_risk": "low", "risk_factors": []}
    
    risk_factors = []
    risk_score = 0
    
    # ë³€ë™ì„± ë¦¬ìŠ¤í¬
    if trend_analysis.volatility > 50:
        risk_factors.append("ë†’ì€ ìˆ˜ìµ ë³€ë™ì„±ìœ¼ë¡œ ì¸í•œ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±")
        risk_score += 30
    elif trend_analysis.volatility > 30:
        risk_factors.append("ì¤‘ê°„ ìˆ˜ì¤€ì˜ ìˆ˜ìµ ë³€ë™ì„±")
        risk_score += 15
    
    # íŠ¸ë Œë“œ ë¦¬ìŠ¤í¬
    if trend_analysis.trend_direction == "decreasing" and trend_analysis.trend_strength > 60:
        risk_factors.append("ê°•í•œ í•˜ë½ íŠ¸ë Œë“œë¡œ ì¸í•œ ìˆ˜ìµ ê°ì†Œ ìœ„í—˜")
        risk_score += 40
    elif trend_analysis.trend_direction == "decreasing":
        risk_factors.append("ìˆ˜ìµ í•˜ë½ ì¶”ì„¸ ì§€ì† ê°€ëŠ¥ì„±")
        risk_score += 20
    
    # ì‹ ë¢°êµ¬ê°„ ë¦¬ìŠ¤í¬
    avg_confidence_range = sum(p.confidence_upper - p.confidence_lower for p in predictions) / len(predictions)
    avg_prediction = sum(p.predicted_profit for p in predictions) / len(predictions)
    
    if avg_prediction != 0:
        relative_uncertainty = abs(avg_confidence_range / avg_prediction) * 100
        if relative_uncertainty > 50:
            risk_factors.append("ì˜ˆì¸¡ ì‹ ë¢°êµ¬ê°„ì´ ë„“ì–´ ë¶ˆí™•ì‹¤ì„± ë†’ìŒ")
            risk_score += 25
        elif relative_uncertainty > 30:
            risk_factors.append("ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±")
            risk_score += 10
    
    # ê³„ì ˆì„± ë¦¬ìŠ¤í¬
    if trend_analysis.seasonality_detected:
        risk_factors.append("ê³„ì ˆì„± íŒ¨í„´ìœ¼ë¡œ ì¸í•œ ì£¼ê¸°ì  ë³€ë™ ìœ„í—˜")
        risk_score += 10
    
    # ë°ì´í„° ë¶€ì¡± ë¦¬ìŠ¤í¬
    # ì´ ì •ë³´ëŠ” ìƒìœ„ì—ì„œ ì „ë‹¬ë˜ì–´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì˜ˆì¸¡ ê°œìˆ˜ë¡œ ì¶”ì •
    if len(predictions) > 6:  # 6ê°œì›” ì´ìƒ ì˜ˆì¸¡ ì‹œ
        risk_factors.append("ì¥ê¸° ì˜ˆì¸¡ìœ¼ë¡œ ì¸í•œ ì •í™•ë„ ì €í•˜ ìœ„í—˜")
        risk_score += 15
    
    # ì „ì²´ ë¦¬ìŠ¤í¬ ë“±ê¸‰ ê²°ì •
    if risk_score >= 60:
        overall_risk = "high"
    elif risk_score >= 30:
        overall_risk = "medium"
    else:
        overall_risk = "low"
    
    return {
        "overall_risk": overall_risk,
        "risk_score": risk_score,
        "risk_factors": risk_factors,
        "confidence_level": max(40, 100 - risk_score),  # ë¦¬ìŠ¤í¬ ì ìˆ˜ì— ë°˜ë¹„ë¡€
        "recommendation": get_risk_recommendation(overall_risk)
    }

def get_risk_recommendation(risk_level: str) -> str:
    """ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ë³„ ê¶Œì¥ì‚¬í•­"""
    
    recommendations = {
        "low": "ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ê³„íšëœ ì „ëµì„ ì‹¤í–‰í•˜ì„¸ìš”.",
        "medium": "ì ë‹¹í•œ ë¦¬ìŠ¤í¬ê°€ ìˆìŠµë‹ˆë‹¤. ëŒ€ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¤€ë¹„í•˜ê³  ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”.",
        "high": "ë†’ì€ ë¶ˆí™•ì‹¤ì„±ì´ ìˆìŠµë‹ˆë‹¤. ë³´ìˆ˜ì  ì ‘ê·¼ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    }
    
    return recommendations.get(risk_level, "ë¦¬ìŠ¤í¬ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def generate_strategic_recommendations(trend_analysis, predictions, current_summary) -> List[str]:
    """ì „ëµì  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    
    recommendations = []
    
    # íŠ¸ë Œë“œ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    if trend_analysis.trend_direction == "increasing":
        if trend_analysis.growth_rate > 20:
            recommendations.append("ğŸ’¡ ê°•ë ¥í•œ ì„±ì¥ì„¸ì…ë‹ˆë‹¤. ë§ˆì¼€íŒ… íˆ¬ìë¥¼ í™•ëŒ€í•˜ê³  ì‹œì¥ ì ìœ ìœ¨ì„ ë†’ì´ì„¸ìš”.")
            recommendations.append("ğŸ’¡ ì„±ì¥ ëª¨ë©˜í…€ì„ í™œìš©í•´ ì‹ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ ì¶œì‹œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        else:
            recommendations.append("ğŸ’¡ ì•ˆì •ì ì¸ ì„±ì¥ì…ë‹ˆë‹¤. ì§€ì† ê°€ëŠ¥í•œ ì„±ì¥ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.")
    elif trend_analysis.trend_direction == "decreasing":
        recommendations.append("ğŸ’¡ ìˆ˜ìµ ê°œì„ ì„ ìœ„í•œ ë¹„ìš© ìµœì í™”ì™€ íš¨ìœ¨ì„± í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
        recommendations.append("ğŸ’¡ ìƒˆë¡œìš´ ìˆ˜ìµì› ë°œêµ´ì´ë‚˜ ì‚¬ì—… ëª¨ë¸ í˜ì‹ ì„ ê²€í† í•˜ì„¸ìš”.")
    else:
        recommendations.append("ğŸ’¡ ì•ˆì •ì ì¸ ìƒí™©ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ì„±ì¥ ê¸°íšŒë¥¼ íƒìƒ‰í•˜ì„¸ìš”.")
    
    # ë³€ë™ì„± ê¸°ë°˜ ê¶Œì¥ì‚¬í•­  
    if trend_analysis.volatility > 40:
        recommendations.append("ğŸ’¡ ìˆ˜ìµ ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•œ ë‹¤ê°í™” ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.")
        recommendations.append("ğŸ’¡ ìœ„í—˜ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ê°•í™”í•˜ê³  ë¹„ìƒ ê³„íšì„ ì¤€ë¹„í•˜ì„¸ìš”.")
    
    # ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    if predictions:
        future_avg = sum(p.predicted_profit for p in predictions) / len(predictions)
        current_avg = current_summary['avg_monthly_profit']
        
        if future_avg > current_avg * 1.2:
            recommendations.append("ğŸ’¡ ìˆ˜ìµ ì¦ê°€ê°€ ì˜ˆìƒë©ë‹ˆë‹¤. ì„±ì¥ íˆ¬ìë¥¼ ëŠ˜ë¦¬ê³  ì¸ë ¥ì„ í™•ì¶©í•˜ì„¸ìš”.")
        elif future_avg < current_avg * 0.8:
            recommendations.append("ğŸ’¡ ìˆ˜ìµ ê°ì†Œê°€ ìš°ë ¤ë©ë‹ˆë‹¤. ë¹„ìš© êµ¬ì¡°ë¥¼ ì ê²€í•˜ê³  íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ì„¸ìš”.")
    
    # ê³„ì ˆì„± ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    if trend_analysis.seasonality_detected:
        recommendations.append("ğŸ’¡ ê³„ì ˆì„± íŒ¨í„´ì„ í™œìš©í•œ ë§ˆì¼€íŒ… íƒ€ì´ë°ê³¼ ì¬ê³  ê´€ë¦¬ë¥¼ ìµœì í™”í•˜ì„¸ìš”.")
    
    # ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ì´ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì¡°ì–¸ ì¶”ê°€
    if not recommendations:
        recommendations.append("ğŸ’¡ ì •ê¸°ì ì¸ ì„±ê³¼ ëª¨ë‹ˆí„°ë§ê³¼ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ê°•í™”í•˜ì„¸ìš”.")
    
    return recommendations

def generate_expense_insights(category_analysis, monthly_patterns, daily_patterns):
    """ì§€ì¶œ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []
    
    if category_analysis:
        # ìŠ¹ì¸ë¥ ì´ ë‚®ì€ ì¹´í…Œê³ ë¦¬
        low_approval = [cat for cat, analysis in category_analysis.items() if analysis['approval_rate'] < 70]
        if low_approval:
            insights.append(f"ğŸš¨ ìŠ¹ì¸ë¥ ì´ ë‚®ì€ ì§€ì¶œ ë¶„ì•¼: {', '.join(low_approval)}")
        
        # ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬
        highest_spending = max(category_analysis.items(), key=lambda x: x[1]['approved_amount'])
        insights.append(f"ğŸ’° ì£¼ìš” ì§€ì¶œ ë¶„ì•¼: {highest_spending[0]} (ì´ {highest_spending[1]['approved_amount']:,.0f}ì›)")
    
    if daily_patterns:
        # ìš”ì¼ë³„ ì§€ì¶œ íŒ¨í„´
        max_day = max(daily_patterns.items(), key=lambda x: x[1]['total_amount'])
        min_day = min(daily_patterns.items(), key=lambda x: x[1]['total_amount'])
        insights.append(f"ğŸ“Š ì§€ì¶œì´ ê°€ì¥ ë§ì€ ìš”ì¼: {max_day[0]} ({max_day[1]['total_amount']:,.0f}ì›)")
        insights.append(f"ğŸ“Š ì§€ì¶œì´ ê°€ì¥ ì ì€ ìš”ì¼: {min_day[0]} ({min_day[1]['total_amount']:,.0f}ì›)")
    
    if len(monthly_patterns) >= 3:
        # ìµœê·¼ 3ê°œì›” íŠ¸ë Œë“œ
        recent_months = sorted(monthly_patterns.keys())[-3:]
        recent_expenses = [monthly_patterns[month]['approved'] for month in recent_months]
        
        if recent_expenses[-1] > recent_expenses[0] * 1.2:
            insights.append("ğŸ“ˆ ìµœê·¼ ì§€ì¶œì´ ì¦ê°€ ì¶”ì„¸ì…ë‹ˆë‹¤. ì˜ˆì‚° ê´€ë¦¬ì— ì£¼ì˜í•˜ì„¸ìš”")
        elif recent_expenses[-1] < recent_expenses[0] * 0.8:
            insights.append("ğŸ“‰ ìµœê·¼ ì§€ì¶œì´ ê°ì†Œ ì¶”ì„¸ì…ë‹ˆë‹¤. ë¹„ìš© ì ˆê°ì´ ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤")
        else:
            insights.append("ğŸ“Š ì§€ì¶œì´ ì•ˆì •ì ì¸ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤")
    
    return insights